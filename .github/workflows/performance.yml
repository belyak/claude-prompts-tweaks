name: Performance Monitoring

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

permissions:
  contents: read
  pull-requests: write

jobs:
  benchmark:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Install uv
      uses: astral-sh/setup-uv@v4
    
    - name: Set up Python
      run: uv python install 3.12
    
    - name: Install dependencies
      run: uv sync --frozen --all-extras
    
    - name: Create benchmarks directory
      run: mkdir -p tests/benchmarks
    
    - name: Create benchmark test file
      run: |
        cat > tests/benchmarks/test_performance.py << 'EOF'
        import pytest
        from claude_prompts_tweaks.main import process_prompts
        
        @pytest.mark.benchmark
        def test_process_prompts_performance(benchmark):
            """Benchmark prompt processing performance."""
            test_data = {"test": "data"} * 100
            result = benchmark(process_prompts, test_data)
            assert result is not None
        EOF
    
    - name: Run benchmarks
      run: |
        uv run pytest tests/benchmarks/ \
          --benchmark-only \
          --benchmark-json=benchmark.json \
          --benchmark-sort=mean \
          --benchmark-min-rounds=10
      continue-on-error: true
    
    - name: Store benchmark result
      uses: benchmark-action/github-action-benchmark@v1
      with:
        tool: 'pytest'
        output-file-path: benchmark.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        comment-on-alert: true
        alert-threshold: '150%'
        comment-always: true
        benchmark-data-dir-path: benchmarks
    
    - name: Profile memory usage
      run: |
        uv run python -m pip install memory-profiler
        echo "from memory_profiler import profile" > profile_test.py
        echo "@profile" >> profile_test.py
        echo "def test_memory():" >> profile_test.py
        echo "    import claude_prompts_tweaks.main" >> profile_test.py
        echo "    # Add memory profiling test here" >> profile_test.py
        echo "test_memory()" >> profile_test.py
        uv run python -m memory_profiler profile_test.py > memory_report.txt 2>&1 || true
    
    - name: Upload performance artifacts
      uses: actions/upload-artifact@v4
      with:
        name: performance-results
        path: |
          benchmark.json
          memory_report.txt
      if: always()

  complexity-analysis:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Install uv
      uses: astral-sh/setup-uv@v4
    
    - name: Set up Python
      run: uv python install 3.12
    
    - name: Install dependencies
      run: uv sync --frozen --all-extras
    
    - name: Run complexity analysis
      run: |
        echo "## Code Complexity Report" > complexity_report.md
        echo "" >> complexity_report.md
        
        echo "### Cyclomatic Complexity" >> complexity_report.md
        uv run radon cc claude_prompts_tweaks -s -a -md >> complexity_report.md
        echo "" >> complexity_report.md
        
        echo "### Maintainability Index" >> complexity_report.md
        uv run radon mi claude_prompts_tweaks -s >> complexity_report.md
        echo "" >> complexity_report.md
        
        echo "### Raw Metrics" >> complexity_report.md
        uv run radon raw claude_prompts_tweaks -s >> complexity_report.md
        echo "" >> complexity_report.md
        
        echo "### Halstead Metrics" >> complexity_report.md
        uv run radon hal claude_prompts_tweaks -f >> complexity_report.md
    
    - name: Check complexity thresholds
      run: |
        # Fail if any function has complexity > 10
        uv run xenon --max-absolute B --max-modules B --max-average A claude_prompts_tweaks
    
    - name: Upload complexity report
      uses: actions/upload-artifact@v4
      with:
        name: complexity-report
        path: complexity_report.md
    
    - name: Comment PR with complexity report
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('complexity_report.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: report
          });